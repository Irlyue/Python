# Pytorch Tricks

## torch.cat && torch.stack

First let's see what the documentation actually tells us:

```python
cat(seq, dim=0, out=None) -> Tensor
"""
Concatenates the given sequence of :attr:seq tensors in the given dimension. 

All tensors must either have the same shape (except in the concatenating dimension) or be empty.
"""

stack(seq, dim=0, out=None) -> Tensor
"""
Concatenates sequence of tensors along a new dimension.
All tensors need to be of the same size.
"""
```

Clear enough. The function `torch.cat` concatenates sequence of tensors **in the given dimension**, which means it will not create a new dimension. The output tensor will have exactly same number of dimensions as the tensors in the given sequence. Some constraints must be satisfied for correct usage:

1. Tensors given in sequence must have same number of dimensions.
2. Only in the specified dimension `dim` could those given tensors have different size.
3. The dimension `dim` must be between $[-d, d)$, where $d$ is the dimension of the tensors to be concatenated.

However, `torch.cat` stack sequence of tensors **along a new dimension**, which means it will actually create a new dimension. Some constraints must be satisfied for correct usage:

1. All tensors need to be of the same size.

> Most of the time you will be using `torch.cat`. Be sure to perform these operations on tensors with same dtype and device.

- code examples

  ```python
  >>> import torch
  >>> s = torch.zeros(2, 10)
  >>> torch.cat((s, s), dim=0).shape
  torch.Size([4, 10])
  >>> torch.cat((s, s), dim=1).shape
  torch.Size([2, 20])
  >>> torch.cat((s, torch.ones(2, 1)), dim=1).shape
  torch.Size([2, 11])
  
  >>> s = torch.zeros(3, 10)
  >>> torch.stack((s, s), dim=0).shape
  torch.Size([2, 3, 10])
  >>> torch.stack((s, s), dim=1).shape
  torch.Size([3, 2, 10])
  >>> torch.stack((s, s), dim=2).shape
  torch.Size([3, 10, 2])
  ```

  

